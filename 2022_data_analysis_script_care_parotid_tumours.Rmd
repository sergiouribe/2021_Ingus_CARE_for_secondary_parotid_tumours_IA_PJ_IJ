---
title: "CARE secondary parotid tumours"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

```{r}
pacman::p_load(tidyverse, 
               gtsummary,
               dlookr, 
               santoku, # to break variables
               DescTools, # for agreement
               irr, # for agreement
               janitor)
```

For wordcloud

```{r}
pacman::p_load(wordcloud, # word-cloud generator 
               SnowballC, # for text stemming
               RColorBrewer, # palette
               wordcloud2, 
               tm) # for text mining
```

```{r}
theme_set(theme_minimal())
```

# Dataset

```{r}
df <- read_csv("https://docs.google.com/spreadsheets/d/e/2PACX-1vRKPzFe2lbF87DNe9SBjuaIb5iMb4nCmgvfdyT4v-NjK-BZBR-HkUIUdgiML3t30EqQ1RCep0sExatK/pub?output=csv")
```

```{r}
names(df)
```

For the wordcloud later

```{r}
text <- df$`Copy and paste the abstract`
```

```{r}
dlookr::diagnose(df)
```

```{r}
df <- df %>%
  mutate(JOURNAL = str_to_title(JOURNAL)) %>% # change the capitalization
  mutate(JOURNAL = str_trim(JOURNAL, side = c("both"))) %>% # remove spaces
  mutate(JOURNAL = str_replace(JOURNAL, "Resaerch", "Research"))  %>% 
  mutate(JOURNAL = str_replace(JOURNAL, "Otolaryngology-Head And Neck Surgery", "Otolaryngology–Head And Neck Surgery")) %>% 
  mutate(JOURNAL = str_replace(JOURNAL, "Otolaryngology–Head And Neck Surgery", "Archives Of Otolaryngology--Head & Neck Surgery")) %>%
  mutate(JOURNAL = str_replace(JOURNAL, "The Journal Of Laryngology & Otology", "The Journal Of Laryngology And Otology"))
```

# Check agreement

How many raters?

```{r}
df %>% 
  tabyl(Reviewer)
```

## Kappa

```{r}
df %>% 
  select(Reviewer, ID,  `CARE Appraisal [Abstract 3b Main symptoms and/or important clinical findings]`:`CARE Appraisal [Key Words 2 2 to 5 key words that identify diagnoses or interventions in this case report, including "case report"]`) %>% # leave only the relevant columns
  filter(Reviewer != "SU") %>%  # remove SU from the rater 
  
  # now reshape the dataset to obtain three columns
  pivot_longer(-c(Reviewer, ID), 
               names_to = "Care_item", 
               values_to = "Care_values") %>% 
  select(-c(Care_item)) %>% 
  
  # now reshape again to obtains the values per rater
  pivot_wider(id_cols = ID, 
              names_from = Reviewer, 
              values_from = Care_values) %>% 
  tidyr::unnest() %>%  # this is to recover the values, check shorturl.at/gpAG3 
  filter(!is.na(IA)) %>% 
  filter(!is.na(PJ)) %>% 
  select(-ID) %>% 
  kappam.fleiss(., detail=TRUE)
```

**The kappa between the rater is .715**

Since they are comparable, I will leave only one + SU

```{r}
df <- df %>% 
  filter(Reviewer %in% c('IA', 'SU'))
```

# EDA

```{r}
df %>% 
  select(Reviewer, JOURNAL, `YEAR published`, `Country of the correspondence author`, `Number of patients`) %>% 
DescTools::Desc()
```

How many papers

```{r}
n_distinct(df$TITLE)
```

From how many journals?

```{r}
n_distinct(df$JOURNAL)
```

List of journals with at least 3 articles

```{r}
df %>% 
  mutate(JOURNAL = fct_lump_min(JOURNAL, min = 3)) %>% 
  count(JOURNAL) %>% 
  arrange(desc(n))
```

Patients distribution by paper

```{r}
df %>% 
  ggplot(aes(x = `Number of patients`)) + 
  geom_histogram(bins = 6)
```

How many patients per paper

```{r}
summary(df$`Number of patients`)
```

How many patients in total

```{r}
sum(df$`Number of patients`)
```

Males and females

```{r}
df %>% 
  pivot_longer(`Males reported`:`Females reported`, 
               names_to = "sex", 
               values_to = "sex_values") %>% 
  ggplot(aes(x = sex_values, 
             fill = "sex")) + 
               
  geom_histogram(bins = 6) + 
  facet_grid(sex ~ .) + 
  theme(legend.position="none")
```

Year of publication

```{r}
df %>% 
  ggplot(aes(x = `YEAR published`)) + 
  geom_histogram(bins = 10)
```

Age of the patients

```{r}
df %>% 
  ggplot(aes(Age)) + 
  geom_histogram(bins = 10)
```

Age of the patients by sex

```{r}
df %>% 
  pivot_longer(`Males reported`:`Females reported`, 
               names_to = "sex", 
               values_to = "sex_values") %>% 
  ggplot(aes(y = sex_values, 
             x = Age, 
             color = sex)) + 
  geom_jitter(alpha = .7) + 
  facet_grid(sex ~ . ) +
  theme(legend.position="none")
```

```{r}
df %>% 
  pivot_longer(`Males reported`:`Females reported`, 
               names_to = "sex", 
               values_to = "sex_values") %>% 
  ggplot(aes(y = Age, 
             x = sex, 
             color = sex)) + 
  geom_boxplot(alpha = .7) + 
  geom_jitter(alpha = .2, width = .2) +
  theme(legend.position="none")
```

# CARE ANALYSIS

Convert the answers to points

Yes = 1

Unclear = .1

No = 0

```{r}
df <- df %>% 
  select(-c(TITLE, Reviewer, `Laika zīmogs`, 
            AUTHORS, `Copy and paste the abstract`, 
            Comments)) %>% 
  # reshape the dataset
  pivot_longer(contains("CARE"), 
               names_to = "CARE_item", 
               values_to = "CARE_value") %>% 
  # create a new column with the values of CARE
  mutate(CARE_value_num = case_when(
    CARE_value == "Yes" ~ "1", 
    CARE_value == "Unclear" ~ "0.1", 
    TRUE ~ "0"
  ))
```

Table 1

Compliance per CARE item

```{r}
df %>% 
  select(CARE_item, CARE_value) %>% 
  mutate(CARE_item = fct_inorder(CARE_item)) %>% # reorder by appeareance
  gtsummary::tbl_summary(by = CARE_value, 
                         percent = "row") %>% 
  modify_header(update = list(
  label ~ '**Characteristic**',
  stat_1 ~ '**No**',
  stat_2 ~ '**Unclear**',
  stat_3 ~ '**Yes**'
))
```

Calculate the average quality per paper

```{r}
df_sum <- df %>%
  janitor::clean_names() %>% # convert the names
  mutate(care_value_num = as.double(care_value_num)) %>%  # change from chr to int
  select(id, care_item, care_value_num) %>% # select only some columns. Later need to join
  # reshapre the dataset
  pivot_wider(names_from = "care_item",
              values_from = "care_value_num") %>%
  relocate(id, .after = last_col()) %>% 
  rowwise() %>% 
  mutate(care_sum = sum(c_across(starts_with("care"))), .keep = "all") %>% 
  ungroup() %>% 
  select(ID = id, care_sum)
  
  
```

Now merge the df_sum

```{r}
df <- left_join(df, df_sum, by = "ID")
```

Remove the df_sum

```{r}
rm(df_sum)
```

Calculate the average quality per year

```{r}
df %>%
  # reshape
  mutate(Decade = floor(`YEAR published` / 10) * 10) %>%
  # mutate(Decade = santoku::chop(`YEAR published`, c(1969, 1979, 1989, 1999, 2009, 2019))) %>%
  pivot_wider(names_from = CARE_item,
              values_from = CARE_value) %>%
  distinct(., ID, .keep_all = TRUE) %>%  # filter unique IDs
  select(ID, Decade, care_sum) %>%
  ggplot(aes(x = as.factor(Decade),
             y = care_sum)) +
  geom_jitter(color = "grey90") +
  geom_boxplot(width = .2, color = "grey60") +
  geom_violin(width = .9, fill = NA) +
  labs(
    title = "Average CARE compliance per decade",
    subtitle = "Median and 25%−75% Quartiles\nDotted line in 2013 marks the publication of the CARE guidelines",
    y = "CARE Compliance",
    x = "Decade"
  ) +
  geom_vline(
    aes(xintercept = 5.3), linetype = "dashed", colour = "red", size = 0.5)
```

Papers published by Journal

```{r}
df %>%
  # reshape
  mutate(Decade = floor(`YEAR published` / 10) * 10) %>%
  # mutate(Decade = santoku::chop(`YEAR published`, c(1969, 1979, 1989, 1999, 2009, 2019))) %>%
  pivot_wider(names_from = CARE_item,
              values_from = CARE_value) %>%
  distinct(., ID, .keep_all = TRUE) %>%  # filter unique IDs
```

# Wordcloud

```{r}

docs <- Corpus(VectorSource(text))
```

```{r}
docs <- docs %>%
  tm_map(removeNumbers) %>%
  tm_map(removePunctuation) %>%
  tm_map(stripWhitespace)
```

```{r}
# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("keywords")) 
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
# docs <- tm_map(docs, stemDocument)
```

```{r}
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
```

```{r}
set.seed(1234)
wordcloud(
  words = d$word,
  freq = d$freq,
  min.freq = 35,
  max.words = 200,
  random.order = TRUE,
  rot.per = 0.35,
  colors = brewer.pal(8, "Dark2")
)
```

Which terms are correlated?

```{r}
findAssocs(dtm, terms = "primary", corlimit = 0.3)
```

papers by journals

```{r}
df %>% 
  mutate(JOURNAL = fct_lump_min(JOURNAL, 4)) %>% 
  count(JOURNAL) %>% 
  arrange(desc(n))
```

# Ingus 1 march 2022

I: Agreement between Ingus and Peteris

0.75

S: what is the quality of the reports?

I: what is the quality before and after 2015

I: difference between journals
